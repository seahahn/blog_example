{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPWvFahhI6gSkeSJ4iDLh4x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seahahn/blog_example/blob/main/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN 코드 예시"
      ],
      "metadata": {
        "id": "_446sIGH2RpZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10개의 클래스로 분류되는 이미지 데이터셋인 [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html)을 사용하여 CNN을 어떻게 구현하는지 알아보자."
      ],
      "metadata": {
        "id": "AsmXqyTX2Qu6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 패키지 및 라이브러리 불러오기"
      ],
      "metadata": {
        "id": "679B31zSkmkt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dAS4x_dtkS8o"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. 시드(seed) 고정하기"
      ],
      "metadata": {
        "id": "fWpXKwZrkwCe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "nVCG1w3QkVZX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. 데이터셋 불러오기 & 훈련 / 검증 / 테스트셋으로 나누기 & 이미지 픽셀값 정규화"
      ],
      "metadata": {
        "id": "WIAtiafikyuK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84cZd9GokVsY",
        "outputId": "ab0b9cef-79e9-494f-b0cf-87cb0f67cd88"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "170508288/170498071 [==============================] - 3s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.astype('float32') / 255.\n",
        "X_test = X_test.astype('float32') / 255."
      ],
      "metadata": {
        "id": "yJBU6EkAkXNM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=.2)"
      ],
      "metadata": {
        "id": "F-8xu5z7kYYv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6VorvQQpa9H",
        "outputId": "074231af-926d-44dd-dc0e-38213f360b0a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "훈련 데이터셋으로 가로 32, 세로 32 픽셀의 컬러(RGB, 3개 채널) 이미지 40000개가 있다."
      ],
      "metadata": {
        "id": "uyD6uSdf2dUT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. 합성곱 신경망 모델 구축"
      ],
      "metadata": {
        "id": "karw74Qfk9UD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "# 특징 추출 부분\n",
        "# 합성곱 층(Conv2D)와 풀링 층(MaxPooling2D)를 번갈아가며 사용\n",
        "model.add(Conv2D(32, (3,3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(32, (3,3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(32, (3,3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "\n",
        "# 분류기 역할의 완전 연결 신경망\n",
        "# 특징 추출 부분을 거쳐온 데이터를 신경망에 입력할 수 있도록 1차원으로 변환\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "# 10개의 클래스 분류이므로 출력층에 10개의 노드를, 활성화 함수로 softmax를 지정\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "CKSoRqzJkZnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conv2D에서 반드시 지정해야 하는 첫 번째 파라미터는 필터의 수(filters), 두 번째는 필터(커널)의 크기(kernel_size)이다.  \n",
        "padding은 'valid' 또는 'same'로 지정 가능하다.  \n",
        "'valid'는 패딩을 적용하지 않아 Conv2D를 지나면 입력된 이미지의 shape이 작아진다.  \n",
        "'same'은 패딩을 적용하여 Conv2D 전후의 이미지 shape이 동일하게 만든다.  \n",
        "  \n",
        "MaxPooling2D에서 풀링할 영역의 크기(pool_size)는 (2, 2)가 기본값이다.  \n",
        "strides 파라미터를 지정하여 몇 칸 단위로 움직이며 풀링을 할지 지정할 수 있다.   기본값은 None으로, 이대로 두면 pool_size와 동일하게 설정된다. 즉, 풀링 영역이 겹치지 않게 된다."
      ],
      "metadata": {
        "id": "O10wrLn02m2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "sxTs4BC2kayT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10개 클래스의 다중 분류 문제이므로 'loss'를 'sparse_categorical_crossentropy'로 지정했다."
      ],
      "metadata": {
        "id": "lmINBkwA2vG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train,\n",
        "          batch_size=128,\n",
        "          validation_data=(X_val, y_val),\n",
        "          epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xi2ZwC8zkcPl",
        "outputId": "0c3200bc-0b6e-434e-bcae-574750b2abc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "313/313 [==============================] - 61s 192ms/step - loss: 1.6996 - accuracy: 0.3819 - val_loss: 1.4316 - val_accuracy: 0.4834\n",
            "Epoch 2/10\n",
            "313/313 [==============================] - 57s 183ms/step - loss: 1.3527 - accuracy: 0.5144 - val_loss: 1.2960 - val_accuracy: 0.5414\n",
            "Epoch 3/10\n",
            "313/313 [==============================] - 57s 183ms/step - loss: 1.2056 - accuracy: 0.5707 - val_loss: 1.1849 - val_accuracy: 0.5756\n",
            "Epoch 4/10\n",
            "313/313 [==============================] - 58s 185ms/step - loss: 1.1056 - accuracy: 0.6077 - val_loss: 1.0814 - val_accuracy: 0.6161\n",
            "Epoch 5/10\n",
            "313/313 [==============================] - 57s 183ms/step - loss: 1.0338 - accuracy: 0.6356 - val_loss: 1.0213 - val_accuracy: 0.6378\n",
            "Epoch 6/10\n",
            "313/313 [==============================] - 58s 185ms/step - loss: 0.9770 - accuracy: 0.6558 - val_loss: 1.0119 - val_accuracy: 0.6476\n",
            "Epoch 7/10\n",
            "313/313 [==============================] - 58s 185ms/step - loss: 0.9164 - accuracy: 0.6798 - val_loss: 0.9586 - val_accuracy: 0.6668\n",
            "Epoch 8/10\n",
            "313/313 [==============================] - 58s 185ms/step - loss: 0.8814 - accuracy: 0.6935 - val_loss: 0.9354 - val_accuracy: 0.6740\n",
            "Epoch 9/10\n",
            "313/313 [==============================] - 58s 185ms/step - loss: 0.8380 - accuracy: 0.7070 - val_loss: 0.9027 - val_accuracy: 0.6925\n",
            "Epoch 10/10\n",
            "313/313 [==============================] - 58s 184ms/step - loss: 0.8020 - accuracy: 0.7193 - val_loss: 0.9292 - val_accuracy: 0.6791\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0ca93f3bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-14z9eIpTim",
        "outputId": "9ddc09b5-85cd-45e1-858b-c083c7ab4537"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 16, 16, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 16, 16, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 8, 8, 32)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 8, 8, 32)          9248      \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 4, 4, 32)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               65664     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 86,346\n",
            "Trainable params: 86,346\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output Shape은 (행 수, 가로 픽셀 수, 세로 픽셀 수, 채널 수) 라고 생각하면 쉽다.  \n",
        "여기서 행(row) 수는 None으로 표시되어 있는데, 이는 특정한 숫자로 지정되지 않았음을 의미한다. 배치 사이즈처럼 32, 64 등 다양한 숫자가 올 수도 있기 때문이다.  \n",
        "채널 수는 각 Conv2D에서 지정한 filters의 값에 맞춰 나온 것을 볼 수 있다.  \n",
        "  \n",
        "MaxPooling2D는 입력으로 들어온 이전의 Conv2D의 shape을 줄였다.  \n",
        "채널의 수는 입력 데이터와 동일하며, 학습되는 가중치가 없기 때문에 Param #도 0으로 표기되었다.  \n",
        "  \n",
        "Flatten에서는 (4, 4, 32)의 데이터가 1차원으로 변환되었기 때문에 4*4*32=512의 shape을 갖게 되었다."
      ],
      "metadata": {
        "id": "hTRAMxkr2xxz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. 모델 평가"
      ],
      "metadata": {
        "id": "iUXXXQ5YlCtP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "di40-mOdkev6",
        "outputId": "e9391b4c-6234-46d6-fcf9-8d1e4b7724d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 4s - loss: 0.9526 - accuracy: 0.6713 - 4s/epoch - 13ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9525882601737976, 0.6712999939918518]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 전이 학습"
      ],
      "metadata": {
        "id": "jEoQ4NNm9k6d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "위의 CIFAR-10 데이터셋을 그대로 사용하되,  \n",
        "모델은 사전 학습 모델(VGG16)을 이용한 전이 학습 모델로 구축"
      ],
      "metadata": {
        "id": "txNfoHMM9s7Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D"
      ],
      "metadata": {
        "id": "m0g2dZjT-LTs"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_model = VGG16(weights='imagenet', include_top=False)"
      ],
      "metadata": {
        "id": "OWo8aFr29_nv",
        "outputId": "2b1346e7-ac3c-476e-a9c2-a2772c17b36c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "58900480/58889256 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(pretrained_model)\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dense(10,activation='softmax'))"
      ],
      "metadata": {
        "id": "66Lip696-OwM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "u7glhO5a-Qe5",
        "outputId": "22fa3ac0-6060-4e4b-bae4-bdf7f411698b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, None, None, 512)   14714688  \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 512)              0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               65664     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,781,642\n",
            "Trainable params: 14,781,642\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "5nn-xnFd-SUz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train,\n",
        "          batch_size=128,\n",
        "          validation_data=(X_val, y_val),\n",
        "          epochs=10)"
      ],
      "metadata": {
        "id": "dUF1hOSX-TKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test, verbose=2)"
      ],
      "metadata": {
        "id": "2n91cqD0-X-u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}